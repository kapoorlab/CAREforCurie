{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import os\n",
    "import glob\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from csbdeep.utils import _raise, Path, axes_check_and_normalize,axes_dict, move_image_axes, move_channel_for_backend, backend_channels_last\n",
    "\n",
    "import tensorflow as tf\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, download_and_extract_zip_file, plot_some\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "from csbdeep.models import CARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alltraining_data(file, axes=None, n_images=None, verbose=False):\n",
    "    \"\"\"Load training data from file in ``.npz`` format.\n",
    "\n",
    "    The data file is expected to have the keys:\n",
    "\n",
    "    - ``X``    : Array of training input images.\n",
    "    - ``Y``    : Array of corresponding target images.\n",
    "    - ``axes`` : Axes of the training images.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        File name\n",
    "\n",
    "    axes: str, optional\n",
    "        Must be provided in case the loaded data does not contain ``axes`` information.\n",
    "    n_images : int, optional\n",
    "        Can be used to limit the number of images loaded from data.\n",
    "    verbose : bool, optional\n",
    "        Can be used to display information about the loaded images.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple( tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`), tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`), str )\n",
    "        Returns two tuples (`X_train`, `Y_train`), (`X_val`, `Y_val`) of training and validation sets\n",
    "        and the axes of the input images.\n",
    "        The tuple of validation data will be ``None`` if ``validation_split = 0``.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    f = np.load(file)\n",
    "    X, Y = f['X'], f['Y']\n",
    "    if axes is None:\n",
    "        axes = f['axes']\n",
    "    axes = axes_check_and_normalize(axes)\n",
    "\n",
    "    assert X.shape == Y.shape\n",
    "    assert len(axes) == X.ndim\n",
    "    assert 'C' in axes\n",
    "    if n_images is None:\n",
    "        n_images = X.shape[0]\n",
    "    assert X.shape[0] == Y.shape[0]\n",
    "    assert 0 < n_images <= X.shape[0]\n",
    "\n",
    "    X, Y = X[:n_images], Y[:n_images]\n",
    "    channel = axes_dict(axes)['C']\n",
    "\n",
    " \n",
    "\n",
    "    X = move_channel_for_backend(X,channel=channel)\n",
    "    Y = move_channel_for_backend(Y,channel=channel)\n",
    "\n",
    "    axes = axes.replace('C','') # remove channel\n",
    "    if backend_channels_last():\n",
    "        axes = axes+'C'\n",
    "    else:\n",
    "        axes = axes[:1]+'C'+axes[1:]\n",
    "\n",
    "    data_val =  None\n",
    "\n",
    "    if verbose:\n",
    "        ax = axes_dict(axes)\n",
    "        n_train = len(X)\n",
    "        image_size = tuple( X.shape[ax[a]] for a in 'TZYX' if a in axes )\n",
    "        n_dim = len(image_size)\n",
    "        n_channel_in, n_channel_out = X.shape[ax['C']], Y.shape[ax['C']]\n",
    "\n",
    "        print('number of training images:\\t', n_train)\n",
    "     \n",
    "        print('image size (%dD):\\t\\t'%n_dim, image_size)\n",
    "        print('axes:\\t\\t\\t\\t', axes)\n",
    "        print('channels in / out:\\t\\t', n_channel_in, '/', n_channel_out)\n",
    "\n",
    "    return (X,Y),  axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images:\t 100\n",
      "image size (2D):\t\t (64, 64)\n",
      "axes:\t\t\t\t SYXC\n",
      "channels in / out:\t\t 1 / 1\n",
      "64 64 1\n"
     ]
    }
   ],
   "source": [
    "(X,Y), axes = load_alltraining_data('/data/u934/service_imagerie/v_kapoor/StarDistTraining/TestUnetSegmentation.npz', verbose=True)\n",
    "\n",
    "c = axes_dict(axes)['C']\n",
    "n_channel_in, n_channel_out = X.shape[c], Y.shape[c]\n",
    "IMG_HEIGHT = X.shape[1]\n",
    "IMG_WIDTH = X.shape[2]\n",
    "IMG_CHANNELS = X.shape[c]\n",
    "print(IMG_HEIGHT , IMG_WIDTH, IMG_CHANNELS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/data/u934/service_imagerie/v_kapoor/StarDistData/TestData/'\n",
    "basedirResultsUnet = '/data/u934/service_imagerie/v_kapoor/StarDistData/JuliaResultsData/Unet/'\n",
    "\n",
    "\n",
    "\n",
    "BaseDirModels = 'models/TestUNet_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images to be segmented =  3\n",
      "Image size =  (512, 640)\n"
     ]
    }
   ],
   "source": [
    "Path = os.path.join(basedir, '*.tif')\n",
    "X = []\n",
    "Names = []\n",
    "\n",
    "filesRaw = glob.glob(Path)\n",
    "\n",
    "for fname in filesRaw:\n",
    "     x = imread(fname)\n",
    "     X.append(x)\n",
    "     Names.append(fname)\n",
    "X.sort\n",
    "\n",
    "\n",
    "axes = 'YX'\n",
    "print('Total number of images to be segmented = ', len(X))\n",
    "print('Image size = ', X[0].shape)\n",
    "count = min(0, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(BaseDirModels, custom_objects={'mean_iou': mean_iou})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have shape (64, 64, 1) but got array with shape (512, 640, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/data/u934/service_imagerie/v_kapoor/anaconda2/envs/tensorflowpy3pt5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                              'argument.')\n\u001b[1;32m   1151\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/u934/service_imagerie/v_kapoor/anaconda2/envs/tensorflowpy3pt5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/u934/service_imagerie/v_kapoor/anaconda2/envs/tensorflowpy3pt5/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    134\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (64, 64, 1) but got array with shape (512, 640, 1)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Segmentedfiles = []\n",
    "sizes_test = []\n",
    "for x in X:\n",
    "    \n",
    "    x = np.zeros((1,) + (x.shape[0], x.shape[1]) + (1,))\n",
    "    segmented = model.predict(x, verbose=0)\n",
    "    Segmentedfiles.append(segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(Names)):\n",
    "   print('Saving file' +  basedirResultsUnet + '%s_' + os.path.basename(Names[i]))\n",
    "   save_tiff_imagej_compatible((basedirResultsUnet + '%s_' + os.path.basename(Names[i])) % model.name, Segmentedfiles[i], axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  i  in  range(0,  count):\n",
    "      plt.figure(figsize=(16,10))\n",
    "      plot_some(np.stack([Segmentedfiles[i]]),\n",
    "          title_list=[['U-Net Segmentation']], \n",
    "          pmin=2,pmax=99.8);\n",
    "      print('Filename = ', Names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflowpy3pt5]",
   "language": "python",
   "name": "conda-env-tensorflowpy3pt5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
